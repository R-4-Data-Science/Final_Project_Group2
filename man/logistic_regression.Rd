% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/Final_Project_Group2.R
\name{logistic_regression}
\alias{logistic_regression}
\title{Logistic Regression}
\usage{
logistic_regression(
  X,
  y,
  learning_rate = 0.01,
  max_iterations = 10000,
  tolerance = 1e-06
)
}
\arguments{
\item{X}{A \code{matrix} containing the predictor variables.}

\item{y}{A \code{vector} representing the observed binary outcomes (0 or 1)
for each observation.}

\item{learning_rate}{The learning rate for the gradient descent algorithm.
Default is 0.01.}

\item{max_iterations}{The maximum number of iterations for the gradient descent
algorithm. Default is 10,000.}

\item{tolerance}{The tolerance for the difference in cost between iterations
to determine convergence. Default is 1e-6.}
}
\value{
A \code{list} containing the optimized coefficients, confusion matrix,
and performance metrics, including prevalence, accuracy, sensitivity, specificity,
false discovery rate, and diagnostic odds ratio.
}
\description{
Fits a logistic regression model to the given data. This function
uses gradient descent to optimize the logistic regression coefficients and
computes several metrics of its performance.
}
\details{
Initializes beta using the least-squares formula:
\code{(X^T * X)^-1 * X^T * y}. Iteratively updates beta in the direction of
negative gradient of the cost function, scaled by the learning rate. Checks
for convergence in each iteration. Returns optimized coefficients beta.
}
\examples{
data(mtcars)
model <- logistic_regression(X = cbind(mtcars$mpg, mtcars$wt), y = mtcars$am)
}
\author{
Cameron Tice
}
